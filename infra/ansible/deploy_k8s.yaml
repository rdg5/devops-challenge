---
- hosts: localhost
  become: yes
  vars:
    ssh_private_key: "/home/ubuntu/.ssh/new-ec2-key"  # Path to the SSH key available on all nodes

  pre_tasks:
    - name: Install pip3 if not installed
      apt:
        name: python3-pip
        state: present
        update_cache: yes

    - name: Ensure boto3 is installed
      pip:
        name: boto3
        state: present
        executable: pip3

  tasks:
    - name: Install Docker
      apt:
        name: docker.io
        state: present
        update_cache: yes

    - name: Start and enable Docker
      systemd:
        name: docker
        enabled: yes
        state: started

    # Retrieve instance metadata, including tags
    - name: Get EC2 instance info
      ec2_instance_info:
        region: "eu-west-1"
      register: instance_info

    # Ensure fallback if Role tag is missing
    - name: Set node_role from EC2 instance tags or default to master
      set_fact:
        node_role: "{{ item.value if item.key == 'Role' else 'master' }}"
      loop: "{{ instance_info.instances[0].tags | dict2items }}"
      when: instance_info.instances[0].tags is defined

    - name: Debug node role
      debug:
        msg: "Node role is {{ node_role }}"

    # Install K3s on Master
    - name: Install k3s on Master
      shell: curl -sfL https://get.k3s.io | sh -s - --write-kubeconfig-mode 644 --disable-agent
      when: node_role == "master"

    # Wait for SSM to propagate token
    - name: Wait for SSM to propagate token
      pause:
        seconds: 30

    # Fetch K3s master IP from SSM
    - name: Get K3s master IP from SSM
      set_fact:
        k3s_master_ip: "{{ lookup('aws_ssm', 'k3s-master-ip', region='eu-west-1') }}"

    # Debug fetched K3s master IP
    - name: Debug K3s master IP
      debug:
        msg: "K3s master IP is {{ k3s_master_ip }}"

    # Fetch K3s node token from SSM
    - name: Get K3s node token from SSM
      set_fact:
        k3s_node_token: "{{ lookup('aws_ssm', 'k3s-node-token', region='eu-west-1') }}"

    # Debug fetched K3s node token
    - name: Debug K3s node token
      debug:
        msg: "K3s node token is {{ k3s_node_token }}"

    - name: Fail if K3s node token is not set
      fail:
        msg: "K3s node token is invalid, cannot proceed"
      when: k3s_node_token == "-" or k3s_node_token == ""

    # Install K3s on Worker and wait for master to be ready
    - name: Wait for K3s master to be ready
      wait_for:
        host: "{{ k3s_master_ip }}"
        port: 6443
        state: started
        timeout: 300
      when: node_role == "worker"

    - name: Install k3s on Worker
      shell: |
        MASTER_IP={{ k3s_master_ip }}
        NODE_TOKEN={{ k3s_node_token }}
        curl -sfL https://get.k3s.io | K3S_URL=https://$MASTER_IP:6443 K3S_TOKEN=$NODE_TOKEN sh -
      when: node_role == "worker"

    # Install Helm on worker nodes
    - name: Install Helm (with retries)
      shell: curl https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash
      retries: 5
      delay: 30
      register: helm_install_result
      until: helm_install_result.rc == 0
      when: node_role == "worker"

    # Fetch K3s kubeconfig from master to localhost, then copy to workers
    - name: Fetch K3s kubeconfig from master
      ansible.builtin.fetch:
        src: /etc/rancher/k3s/k3s.yaml
        dest: /tmp/k3s.yaml
        flat: yes
        validate_checksum: no  # Disable checksum validation
      delegate_to: "{{ k3s_master_ip }}"
      when: node_role == "master"
      vars:
        ansible_ssh_common_args: '-o StrictHostKeyChecking=no'

    # Copy K3s kubeconfig from localhost to worker nodes
    - name: Copy K3s kubeconfig to worker nodes
      copy:
        src: /tmp/k3s.yaml
        dest: /etc/rancher/k3s/k3s.yaml
        owner: ubuntu
        mode: '0644'
      when: node_role == "worker"

    # Wait for K3s control plane to be ready
    - name: Wait for K3s control plane to be ready on worker nodes
      shell: |
        kubectl --kubeconfig=/etc/rancher/k3s/k3s.yaml get nodes
      register: k3s_status
      retries: 10
      delay: 15
      until: k3s_status.rc == 0
      when: node_role == "worker"

    # Helm releases for Prometheus and Grafana
    - name: Install Prometheus Operator with Helm (via NodePort)
      shell: |
        helm upgrade --install prometheus-operator prometheus-community/kube-prometheus-stack \
        --set prometheus.service.type=NodePort \
        --set prometheus.service.nodePort=30003 \
        --wait
      environment:
        KUBECONFIG: "/etc/rancher/k3s/k3s.yaml"
      when: node_role == "worker"

    - name: Install Grafana with Helm (NodePort 30002 and provisioned dashboards)
      shell: |
        helm upgrade --install grafana grafana/grafana \
        --set adminPassword='your-admin-password' \
        --set service.type=NodePort \
        --set service.nodePort=30002 \
        --set extraVolumes[0].name=grafana-provisioning \
        --set extraVolumes[0].hostPath.path=/etc/grafana/provisioning \
        --set extraVolumes[0].hostPath.type=Directory \
        --set extraVolumes[1].name=grafana-dashboard-vol \
        --set extraVolumes[1].hostPath.path=/var/lib/grafana/dashboards \
        --set extraVolumes[1].hostPath.type=Directory \
        --set extraVolumeMounts[0].name=grafana-provisioning \
        --set extraVolumeMounts[0].mountPath=/etc/grafana/provisioning \
        --set extraVolumeMounts[1].name=grafana-dashboard-vol \
        --set extraVolumeMounts[1].mountPath=/var/lib/grafana/dashboards \
        --wait
      environment:
        KUBECONFIG: "/etc/rancher/k3s/k3s.yaml"
      when: node_role == "worker"

    - name: Wait for Grafana pod to be ready
      shell: kubectl wait --for=condition=ready pod -l app.kubernetes.io/name=grafana  --timeout=120s
      changed_when: false
      when:
        - node_role == "worker"
        - inventory_hostname == groups['worker'][0]

    # Deploying birdImage and birdAPI Helm charts
    - name: Deploy birdImage API using Helm
      shell: |
        helm upgrade --install birdimageapi /home/ubuntu/devops-challenge/helm-charts/birdImage/ \
        -f /home/ubuntu/devops-challenge/helm-charts/birdImage/values-amd64.yaml \
        --namespace default
      environment:
        KUBECONFIG: "/etc/rancher/k3s/k3s.yaml"
      when: node_role == "worker"

    - name: Deploy bird API using Helm
      shell: |
        helm upgrade --install birdapi /home/ubuntu/devops-challenge/helm-charts/bird/ \
        -f /home/ubuntu/devops-challenge/helm-charts/bird/values-amd64.yaml \
        --namespace default \
        --set birdImageApiReleaseName=birdimageapi
      environment:
        KUBECONFIG: "/etc/rancher/k3s/k3s.yaml"
      when: node_role == "worker"
